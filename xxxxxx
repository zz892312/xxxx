# OpenShift Service Mesh & KServe Deployment – What We Learned

## Validation of Service Mesh Impact on OpenShift Routes

### What Happens

Once a namespace is added to the `ServiceMeshMemberRoll`:

- OpenShift Routes that point directly to services **stop working**
- All external traffic is rerouted through the Istio Ingress Gateway
- OpenShift’s built-in mTLS with routes doesn’t work anymore

### Why This Happens

Istio sidecars kick in and take over traffic control:

- All external access has to go through the `istio-ingressgateway`
- Internal services are expected to use Istio’s mTLS
- OpenShift Routes bypass Istio, so the traffic doesn’t get handled the way Istio expects—and fails

---

## KServe Deployment Modes: Trade-offs

### RawDeployment Mode (No Istio/Knative)

Here’s an example configuration:

<pre><code>kserve:
  defaultDeploymentMode: RawDeployment
  managementState: Managed
  serving:
    managementState: Removed  # Turns off Knative
</code></pre>

### Why We Might Want This

- **OpenShift Route Compatibility**: Native routes work as expected
- **Network Flexibility**: Standard Ingress/LoadBalancers are usable
- **Multi-Volume Support**: We can mount multiple volumes easily
- **Simpler Architecture**: No Knative or Istio to manage

### What We Miss Out On

| Feature                  | RawDeployment | Serverless Mode (Knative/Istio) |
|--------------------------|---------------|----------------------------------|
| Scale-to-Zero            | No            | Yes                              |
| Request-Based Scaling    | No            | Yes                              |
| Canary Deployments       | No            | Yes                              |
| Automatic mTLS           | No            | Yes                              |
| Advanced Routing         | No            | Yes (retries, timeouts, etc.)    |
| Serverless Billing Model | No            | Yes                              |

---

## Some Things to Watch Out For

### Scaling

- We'll need to configure Horizontal Pod Autoscalers (HPAs) manually
- Scaling is based on CPU/memory metrics, not HTTP request volume

### Security

- TLS termination must be handled manually at the OpenShift Route level
- For service-to-service encryption, we'll need to manually configure mTLS or use other mechanisms

### Platform Constraints

- Port conflicts can happen (e.g., Istio might already bind to port 8888)
- RawDeployment mode is **not fully supported** on single-node OpenShift clusters

---

## When to Use RawDeployment

RawDeployment is a good fit if:

- When we want to keep using existing OpenShift Routes or LoadBalancers
- When we don't need traffic-splitting features like canary or A/B testing
- When we're comfortable handling autoscaling and security manually

---

## Migration Checklist

- Set `serving.managementState` to `Removed` to disable Knative
- Set KServe’s `defaultDeploymentMode` to `RawDeployment`
- Configure Kubernetes HPA for autoscaling
- Test OpenShift Routes to confirm they’re working
- Set up TLS manually if required

---

[RawDeployment mode has limited support – Red Hat Documentation](https://access.redhat.com)


https://docs.redhat.com/en/documentation/red_hat_openshift_serverless/1.31/html/integrations/serverless-ossm-setup

https://access.redhat.com/solutions/7078183
