CUDA_VISIBLE_DEVICES=0 vllm serve /path/to/qwen-8b \
  --port 8000 \
  --enable-prefix-caching \
  --enable-chunked-prefill \
  --max-num-seqs 256 &
GUIDELLM__MAX_CONCURRENCY=10000 guidellm benchmark \
  --target "http://localhost:8000" \
  --processor "/path/to/model" \
  --profile constant \
  --rate 5000 \
  --max-seconds 60 \
  --data "prompt_tokens_min=300,prompt_tokens_max=500,output_tokens_min=25,output_tokens_max=50"


GUIDELLM__MAX_CONCURRENCY=10000 \
GUIDELLM__MAX_WORKER_PROCESSES=32 \
GUIDELLM__MAX_ADD_REQUESTS_PER_LOOP=100 \
GUIDELLM__DEFAULT_ASYNC_LOOP_SLEEP=0.00001 \
guidellm benchmark \
  --target "http://localhost:8000" \
  --processor "/path/to/model" \
  --profile constant \
  --rate 5000 \
  --max-seconds 60 \
  --data "prompt_tokens_min=300,prompt_tokens_max=500,output_tokens_min=25,output_tokens_max=50"



for i in {1..8}; do
  GUIDELLM__MAX_CONCURRENCY=2000 \
  guidellm benchmark \
    --target "http://localhost:8000" \
    --processor "/path/to/model" \
    --profile constant \
    --rate 625 \
    --max-seconds 60 \
    --output-path "./results_$i.json" \
    --data "prompt_tokens_min=300,prompt_tokens_max=500,output_tokens_min=25,output_tokens_max=50" &
done

wait
echo "All done"



# Terminal 1 â€” your script hammering at 5000 RPS
python your_load_script.py

# Terminal 2 â€” GuideLLM capturing LLM-specific metrics
guidellm benchmark \
  --target "http://localhost:8000" \
  --processor "/path/to/model" \
  --profile constant \
  --rate 500 \
  --max-seconds 60 \
  --data "prompt_tokens_min=300,prompt_tokens_max=500,output_tokens_min=25,output_tokens_max=50"

# Terminal 3 â€” vLLM metrics (cache hit rate, queue depth)
watch -n2 "curl -s http://localhost:8000/metrics | grep -E 'running|waiting|cache'"







Iâ€™ll continue from Samsonâ€™s vision statement and add some additional context around the CLI and how it fits into the overall architecture.

From the GitHub inference deployment pipeline integration perspective, we already had a templating layer in place. This is not something new.

It has been powering capabilities such as dynamic image injection at runtime across different environments â€” which Helios depends on â€” along with resource validation and configuration standardization.

As we continue to expose more KServe capabilities, the inference service contract may evolve. This includes scenarios such as vault bindings, authentication components, and other configuration extensions. Supporting these capabilities requires a flexible templating layer underneath.

Previously, this templating layer was embedded inside the pipeline and not directly exposed to users.

The Pharos CLI is designed to surface that layer and make it accessible.

It consists of two main components:

A templating engine that renders the raw deployment templates, allowing users to see and test configuration changes directly.

A deployment and permission management layer that handles controlled deployments to lower environments and enforces cluster-level policies.

By integrating this into Jupyter, we allow users to experiment earlier â€” before full GitHub onboarding â€” while still operating within the guardrails of our internal cluster governance model.

This makes the system more transparent, more flexible, and easier to evolve as we introduce new capabilities.


We plan to release the CLI by the end of this week, and because model hosting â€” especially for open-source models â€” is not always plug-and-play, with different models, handlers, configurations, and runtime engine versions requiring different setups, we intentionally avoid locking you into a fixed framework, keeping the options open to support your exploration, and if you need help with configuration or encounter issues, the AIFarm community is there to assist, we will fix bugs, add runtimes as needed, and incorporate your feedback as improvements.

Why Pharos CLI?

As KServe capabilities evolve (e.g., vault bindings, authentication components, configuration extensions), a flexible templating layer becomes critical.

Pharos CLI surfaces this layer and makes it accessible for earlier testing and experimentation.

Core Components

Templating Engine

Renders raw deployment templates

Exposes the configuration layer for transparency

Deployment & Permission Management

Manages controlled deployments to lower environments

Enforces cluster-level governance

Key Benefit

Enables early experimentation (via Jupyter integration) before full GitHub onboarding â€” while maintaining cluster policy controls.


guidellm benchmark \
  --target "http://localhost:8000" \
  --processor "/path/to/your/local/model" \
  --profile constant \
  --rate 5000 \
  --max-seconds 60 \
  --data '{"prompt_tokens_min": 300, "prompt_tokens_max": 500, "output_tokens_min": 25, "output_tokens_max": 50}'


watch -n2 "curl -s http://localhost:8000/metrics | grep -E 'running|waiting|cache|tokens'"
```

You'll see a clear pattern as RPS climbs:
```
Low RPS  â†’ num_requests_waiting â‰ˆ 0, cache usage low
Mid RPS  â†’ batch fills up, cache usage 70-80%, throughput peaks
High RPS â†’ waiting queue grows, TTFT spikes â†’ saturation point

name: Track Sub-Issue Completion

on:
  issues:
    types: [closed]

permissions:
  issues: write
  contents: read

jobs:
  update-parent:
    runs-on: ubuntu-latest
    if: contains(github.event.issue.labels.*.name, 'sub-issue')
    
    steps:
      - name: Extract parent issue number
        id: extract_parent
        uses: actions/github-script@v7
        with:
          script: |
            const body = context.payload.issue.body;
            const match = body.match(/\*\*Parent Issue:\*\*\s*#(\d+)/);
            
            if (!match) {
              core.setFailed('Could not find parent issue reference');
              return null;
            }
            
            const parentNumber = parseInt(match[1]);
            core.setOutput('parent_number', parentNumber);
            
            // Extract compatibility type
            const compatMatch = context.payload.issue.title.match(/\[(.*?)\]\s*(ADT|Jupyter|Airflow)/);
            const compat = compatMatch ? compatMatch[2] : 'Unknown';
            core.setOutput('compat', compat);
            
            return { parentNumber, compat };

      - name: Update parent issue
        uses: actions/github-script@v7
        env:
          PARENT_NUMBER: ${{ steps.extract_parent.outputs.parent_number }}
          COMPAT: ${{ steps.extract_parent.outputs.compat }}
        with:
          script: |
            const parentNumber = parseInt(process.env.PARENT_NUMBER);
            const compat = process.env.COMPAT;
            const subIssueNumber = context.issue.number;
            const subIssueTitle = context.payload.issue.title;
            
            // Remove the TODO label for this compatibility
            const todoLabel = `todo-${compat.toLowerCase()}`;
            
            try {
              await github.rest.issues.removeLabel({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: parentNumber,
                name: todoLabel
              });
            } catch (error) {
              console.log(`Label ${todoLabel} not found or already removed`);
            }
            
            // Add completed label
            const completedLabel = `completed-${compat.toLowerCase()}`;
            await github.rest.issues.addLabels({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: parentNumber,
              labels: [completedLabel]
            });
            
            // Add completion comment to parent issue
            const comment = `âœ… **${compat} Integration Completed**

Sub-issue #${subIssueNumber} (${subIssueTitle}) has been closed.

The ${compat} compatibility integration is now complete.`;

            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: parentNumber,
              body: comment
            });

      - name: Check if all sub-issues completed
        uses: actions/github-script@v7
        env:
          PARENT_NUMBER: ${{ steps.extract_parent.outputs.parent_number }}
        with:
          script: |
            const parentNumber = parseInt(process.env.PARENT_NUMBER);
            
            // Get parent issue
            const parentIssue = await github.rest.issues.get({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: parentNumber
            });
            
            // Check for any remaining TODO labels
            const labels = parentIssue.data.labels.map(l => l.name);
            const todoLabels = labels.filter(l => l.startsWith('todo-'));
            
            if (todoLabels.length === 0) {
              // All sub-issues completed!
              await github.rest.issues.removeLabel({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: parentNumber,
                name: 'in-progress'
              });
              
              await github.rest.issues.addLabels({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: parentNumber,
                labels: ['completed']
              });
              
              // Get requester info from parent issue
              const body = parentIssue.data.body;
              const emailMatch = body.match(/### Requester Email\s*\n\s*(.+)/);
              const appNameMatch = body.match(/### Application Name\s*\n\s*(.+)/);
              const email = emailMatch ? emailMatch[1].trim() : '';
              const appName = appNameMatch ? appNameMatch[1].trim() : '';
              
              const completionComment = `ðŸŽ‰ **All Compatibility Integrations Completed!**

All sub-issues have been completed. The onboarding process for this application is now complete.

**Completed Integrations:**
${labels.filter(l => l.startsWith('completed-')).map(l => `- âœ… ${l.replace('completed-', '').toUpperCase()}`).join('\n')}

@${parentIssue.data.user.login} Your application is ready!

---
*Notification sent to: ${email}*`;

              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: parentNumber,
                body: completionComment
              });
              
              // Close the parent issue
              await github.rest.issues.update({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: parentNumber,
                state: 'closed'
              });
            }
