{
  "dashboard": {
    "id": null,
    "title": "Triton Inference Server Performance Dashboard",
    "tags": ["triton", "inference", "ml", "monitoring"],
    "timezone": "browser",
    "refresh": "5s",
    "time": {
      "from": "now-30m",
      "to": "now"
    },
    "panels": [
      {
        "id": 1,
        "title": "Service Health Overview",
        "type": "stat",
        "targets": [
          {
            "expr": "up{job=\"triton-inference\"}",
            "legendFormat": "Service Status"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {
              "mode": "thresholds"
            },
            "thresholds": {
              "steps": [
                {"color": "red", "value": 0},
                {"color": "green", "value": 1}
              ]
            },
            "mappings": [
              {"options": {"0": {"text": "DOWN"}}, "type": "value"},
              {"options": {"1": {"text": "UP"}}, "type": "value"}
            ]
          }
        },
        "gridPos": {"h": 4, "w": 6, "x": 0, "y": 0}
      },
      {
        "id": 2,
        "title": "Total Inference Requests",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(rate(nv_inference_request_success_total[5m])) + sum(rate(nv_inference_request_failure_total[5m]))",
            "legendFormat": "Requests/sec"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "reqps",
            "color": {"mode": "palette-classic"}
          }
        },
        "gridPos": {"h": 4, "w": 6, "x": 6, "y": 0}
      },
      {
        "id": 3,
        "title": "Success Rate",
        "type": "stat",
        "targets": [
          {
            "expr": "sum(rate(nv_inference_request_success_total[5m])) / (sum(rate(nv_inference_request_success_total[5m])) + sum(rate(nv_inference_request_failure_total[5m]))) * 100",
            "legendFormat": "Success Rate %"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent",
            "color": {"mode": "thresholds"},
            "thresholds": {
              "steps": [
                {"color": "red", "value": 0},
                {"color": "yellow", "value": 95},
                {"color": "green", "value": 99}
              ]
            }
          }
        },
        "gridPos": {"h": 4, "w": 6, "x": 12, "y": 0}
      },
      {
        "id": 4,
        "title": "Active Models",
        "type": "stat",
        "targets": [
          {
            "expr": "count(count by (model)(nv_inference_request_success_total))",
            "legendFormat": "Models Loaded"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "color": {"mode": "palette-classic"}
          }
        },
        "gridPos": {"h": 4, "w": 6, "x": 18, "y": 0}
      },
      {
        "id": 5,
        "title": "Request Rate by Model",
        "type": "timeseries",
        "targets": [
          {
            "expr": "sum(rate(nv_inference_request_success_total[5m])) by (model)",
            "legendFormat": "{{model}} - Success"
          },
          {
            "expr": "sum(rate(nv_inference_request_failure_total[5m])) by (model)",
            "legendFormat": "{{model}} - Failure"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "reqps",
            "custom": {
              "drawStyle": "line",
              "lineInterpolation": "linear",
              "showPoints": "never",
              "stacking": {"mode": "none"}
            }
          }
        },
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 4}
      },
      {
        "id": 6,
        "title": "Inference Latency Distribution",
        "type": "timeseries",
        "targets": [
          {
            "expr": "histogram_quantile(0.50, sum(rate(nv_inference_request_duration_us_bucket[5m])) by (le, model))",
            "legendFormat": "{{model}} - P50"
          },
          {
            "expr": "histogram_quantile(0.90, sum(rate(nv_inference_request_duration_us_bucket[5m])) by (le, model))",
            "legendFormat": "{{model}} - P90"
          },
          {
            "expr": "histogram_quantile(0.99, sum(rate(nv_inference_request_duration_us_bucket[5m])) by (le, model))",
            "legendFormat": "{{model}} - P99"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "µs",
            "custom": {
              "drawStyle": "line",
              "lineInterpolation": "linear",
              "showPoints": "never"
            }
          }
        },
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 4}
      },
      {
        "id": 7,
        "title": "GPU Utilization",
        "type": "timeseries",
        "targets": [
          {
            "expr": "nv_gpu_utilization",
            "legendFormat": "GPU {{gpu_uuid}}"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent",
            "max": 100,
            "min": 0,
            "custom": {
              "drawStyle": "line",
              "lineInterpolation": "linear",
              "fillOpacity": 10
            }
          }
        },
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 12}
      },
      {
        "id": 8,
        "title": "GPU Memory Usage",
        "type": "timeseries",
        "targets": [
          {
            "expr": "nv_gpu_memory_used_bytes / nv_gpu_memory_total_bytes * 100",
            "legendFormat": "GPU {{gpu_uuid}} Memory %"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent",
            "max": 100,
            "min": 0,
            "custom": {
              "drawStyle": "line",
              "lineInterpolation": "linear",
              "fillOpacity": 10
            }
          }
        },
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 12}
      },
      {
        "id": 9,
        "title": "Queue Time by Model",
        "type": "timeseries",
        "targets": [
          {
            "expr": "histogram_quantile(0.50, sum(rate(nv_inference_queue_duration_us_bucket[5m])) by (le, model))",
            "legendFormat": "{{model}} - Queue P50"
          },
          {
            "expr": "histogram_quantile(0.90, sum(rate(nv_inference_queue_duration_us_bucket[5m])) by (le, model))",
            "legendFormat": "{{model}} - Queue P90"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "µs",
            "custom": {
              "drawStyle": "line",
              "lineInterpolation": "linear"
            }
          }
        },
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 20}
      },
      {
        "id": 10,
        "title": "Compute Time by Model",
        "type": "timeseries",
        "targets": [
          {
            "expr": "histogram_quantile(0.50, sum(rate(nv_inference_compute_duration_us_bucket[5m])) by (le, model))",
            "legendFormat": "{{model}} - Compute P50"
          },
          {
            "expr": "histogram_quantile(0.90, sum(rate(nv_inference_compute_duration_us_bucket[5m])) by (le, model))",
            "legendFormat": "{{model}} - Compute P90"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "µs",
            "custom": {
              "drawStyle": "line",
              "lineInterpolation": "linear"
            }
          }
        },
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 20}
      },
      {
        "id": 11,
        "title": "Model Execution Count",
        "type": "table",
        "targets": [
          {
            "expr": "sum(nv_inference_request_success_total) by (model)",
            "legendFormat": "{{model}}",
            "format": "table",
            "instant": true
          }
        ],
        "fieldConfig": {
          "defaults": {
            "custom": {
              "align": "left",
              "displayMode": "basic"
            }
          }
        },
        "gridPos": {"h": 8, "w": 8, "x": 0, "y": 28}
      },
      {
        "id": 12,
        "title": "Error Rate by Model",
        "type": "timeseries",
        "targets": [
          {
            "expr": "sum(rate(nv_inference_request_failure_total[5m])) by (model)",
            "legendFormat": "{{model}} - Error Rate"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "reqps",
            "color": {"mode": "palette-classic"},
            "custom": {
              "drawStyle": "line",
              "lineInterpolation": "linear"
            }
          }
        },
        "gridPos": {"h": 8, "w": 8, "x": 8, "y": 28}
      },
      {
        "id": 13,
        "title": "Memory Usage (System)",
        "type": "timeseries",
        "targets": [
          {
            "expr": "nv_cpu_memory_used_bytes / nv_cpu_memory_total_bytes * 100",
            "legendFormat": "CPU Memory %"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "unit": "percent",
            "max": 100,
            "min": 0,
            "custom": {
              "drawStyle": "line",
              "lineInterpolation": "linear",
              "fillOpacity": 10
            }
          }
        },
        "gridPos": {"h": 8, "w": 8, "x": 16, "y": 28}
      },
      {
        "id": 14,
        "title": "Request Size Distribution",
        "type": "heatmap",
        "targets": [
          {
            "expr": "sum(rate(nv_inference_request_size_bytes_bucket[5m])) by (le)",
            "legendFormat": "{{le}}"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "custom": {
              "hideFrom": {
                "legend": false,
                "tooltip": false,
                "vis": false
              }
            }
          }
        },
        "gridPos": {"h": 8, "w": 12, "x": 0, "y": 36}
      },
      {
        "id": 15,
        "title": "Response Size Distribution",
        "type": "heatmap",
        "targets": [
          {
            "expr": "sum(rate(nv_inference_response_size_bytes_bucket[5m])) by (le)",
            "legendFormat": "{{le}}"
          }
        ],
        "fieldConfig": {
          "defaults": {
            "custom": {
              "hideFrom": {
                "legend": false,
                "tooltip": false,
                "vis": false
              }
            }
          }
        },
        "gridPos": {"h": 8, "w": 12, "x": 12, "y": 36}
      }
    ]
  }
}