from flask import Flask, request, jsonify, render_template_string
from flask_cors import CORS
import time
import yaml
import os

app = Flask(__name__)
CORS(app)

# Simple in-memory user storage (use a proper database in production)
users = {
    "admin": {
        "password": "password123",
        "name": "Administrator",
        "email": "admin@company.com",
        "role": "admin",
        "namespace": "default",
        "created": "2024-01-15"
    },
    "user": {
        "password": "test123",
        "name": "John Doe",
        "email": "john.doe@company.com",
        "role": "developer",
        "namespace": "dev-team",
        "created": "2024-02-20"
    }
}

# Mock inference services data
inference_services = {
    "default": [
        {
            "name": "llama-7b-service",
            "status": "Running",
            "runtime": "pytorch",
            "created": "2024-07-10",
            "replicas": 2,
            "endpoint": "http://llama-7b-service.default.svc.cluster.local/v1/models/llama-7b-service",
            "resources": {"gpu": 2, "cpu": "4", "memory": "8Gi"}
        },
        {
            "name": "bert-classifier",
            "status": "Running",
            "runtime": "tensorflow",
            "created": "2024-07-12",
            "replicas": 1,
            "endpoint": "http://bert-classifier.default.svc.cluster.local/v1/models/bert-classifier",
            "resources": {"gpu": 1, "cpu": "2", "memory": "4Gi"}
        },
        {
            "name": "image-detection",
            "status": "Pending",
            "runtime": "onnx",
            "created": "2024-07-15",
            "replicas": 1,
            "endpoint": "http://image-detection.default.svc.cluster.local/v1/models/image-detection",
            "resources": {"gpu": 1, "cpu": "2", "memory": "6Gi"}
        }
    ],
    "dev-team": [
        {
            "name": "sentiment-analyzer",
            "status": "Running",
            "runtime": "pytorch",
            "created": "2024-07-08",
            "replicas": 1,
            "endpoint": "http://sentiment-analyzer.dev-team.svc.cluster.local/v1/models/sentiment-analyzer",
            "resources": {"gpu": 1, "cpu": "2", "memory": "4Gi"}
        },
        {
            "name": "chatbot-model",
            "status": "Error",
            "runtime": "pytorch",
            "created": "2024-07-14",
            "replicas": 0,
            "endpoint": "http://chatbot-model.dev-team.svc.cluster.local/v1/models/chatbot-model",
            "resources": {"gpu": 2, "cpu": "4", "memory": "8Gi"}
        }
    ]
}

# Store active sessions (use Redis or proper session management in production)
sessions = {}

@app.route('/')
def index():
    return render_template_string(open('index.html').read())

@app.route('/api/login', methods=['POST'])
def login():
    data = request.get_json()
    username = data.get('username')
    password = data.get('password')
    
    if username in users and users[username]["password"] == password:
        session_token = f"session_{username}_{int(time.time())}"
        sessions[session_token] = username
        return jsonify({
            "success": True,
            "token": session_token,
            "user": {
                "username": username,
                "name": users[username]["name"],
                "email": users[username]["email"],
                "role": users[username]["role"],
                "namespace": users[username]["namespace"],
                "created": users[username]["created"]
            },
            "message": "Login successful"
        })
    else:
        return jsonify({
            "success": False,
            "message": "Invalid credentials"
        }), 401

@app.route('/api/services', methods=['GET'])
def get_services():
    # In a real app, you'd verify the session token
    username = request.args.get('username', 'admin')
    if username in users:
        namespace = users[username]["namespace"]
        services = inference_services.get(namespace, [])
        return jsonify({
            "success": True,
            "services": services,
            "namespace": namespace
        })
    else:
        return jsonify({
            "success": False,
            "message": "User not found"
        }), 404

@app.route('/api/generate-yaml', methods=['POST'])
def generate_yaml():
    data = request.get_json()
    
    # Generate Kubernetes inference service YAML
    yaml_content = {
        "apiVersion": "serving.kserve.io/v1beta1",
        "kind": "InferenceService",
        "metadata": {
            "name": data.get('serviceName', 'inference-service'),
            "namespace": "default"
        },
        "spec": {
            "predictor": {
                "containers": [
                    {
                        "name": "predictor",
                        "image": f"inference-runtime:{data.get('runtime', 'pytorch')}",
                        "env": [
                            {
                                "name": "MODEL_PATH",
                                "value": data.get('s3Url', 's3://model-bucket/model')
                            }
                        ],
                        "resources": {
                            "requests": {
                                "cpu": data.get('cpuRequest', '1'),
                                "memory": data.get('memoryRequest', '2Gi'),
                                "nvidia.com/gpu": data.get('gpuRequest', '1')
                            },
                            "limits": {
                                "cpu": data.get('cpuRequest', '1'),
                                "memory": data.get('memoryRequest', '2Gi'),
                                "nvidia.com/gpu": data.get('gpuRequest', '1')
                            }
                        }
                    }
                ]
            }
        }
    }
    
    try:
        yaml_string = yaml.dump(yaml_content, default_flow_style=False)
        return jsonify({
            "success": True,
            "yaml": yaml_string
        })
    except Exception as e:
        return jsonify({
            "success": False,
            "error": str(e)
        }), 500

@app.route('/api/deploy', methods=['POST'])
def deploy():
    data = request.get_json()
    yaml_content = data.get('yaml')
    
    # Simulate deployment process
    time.sleep(2)  # Simulate deployment time
    
    return jsonify({
        "success": True,
        "message": "Deployment completed successfully!",
        "status": "Running",
        "endpoint": f"http://inference-service.default.svc.cluster.local/v1/models/{data.get('serviceName', 'inference-service')}"
    })

@app.route('/api/deployment-status', methods=['GET'])
def deployment_status():
    # Simulate deployment progress
    import random
    stages = [
        "Validating YAML configuration...",
        "Creating Kubernetes resources...",
        "Pulling container images...",
        "Allocating GPU resources...",
        "Starting inference service...",
        "Running health checks...",
        "Deployment completed!"
    ]
    
    stage = request.args.get('stage', 0)
    stage = int(stage)
    
    if stage < len(stages):
        return jsonify({
            "stage": stage,
            "message": stages[stage],
            "progress": int((stage / len(stages)) * 100),
            "completed": False
        })
    else:
        return jsonify({
            "stage": stage,
            "message": "Deployment successful!",
            "progress": 100,
            "completed": True
        })

if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5000)